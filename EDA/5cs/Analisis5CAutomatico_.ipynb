{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3312ed12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Cargando datos...\n",
      "‚úÖ Datos cargados: 14148 registros, 30 variables\n",
      "   Car√°cter: 4 variables\n",
      "   Capacidad: 1 variables\n",
      "   Capital: 2 variables\n",
      "   Condiciones: 2 variables\n",
      "   Colateral: 3 variables\n",
      "üìã Total variables 5C's: 12\n",
      "üîç Calculando importancia de variables (solo 5C's)...\n",
      "üîÑ Preprocesando variables de las 5C's...\n",
      "   Variables preprocesadas: 12\n",
      "‚öñÔ∏è Calculando pesos autom√°ticos para las 5C...\n",
      "üå≤ Calculando importancia con Random Forest...\n",
      "üîÑ Preprocesando variables de las 5C's...\n",
      "   Variables preprocesadas: 12\n",
      "üìä Calculando correlaciones (corregido)...\n",
      "\n",
      "üìå Correlaciones detectadas:\n",
      "      Categoria                Variable  Correlacion\n",
      "3      Car√°cter        exp_cred_interna     0.104693\n",
      "9     Colateral        montogarantialiq     0.053281\n",
      "4     Capacidad                cap_pago     0.021704\n",
      "6       Capital                  deudas     0.021082\n",
      "0      Car√°cter     antigudad_domicilio     0.011385\n",
      "1      Car√°cter    antiguedad_actividad     0.007819\n",
      "10    Colateral        montogarantiapre     0.004818\n",
      "8   Condiciones      comercio_en_region     0.002520\n",
      "7   Condiciones  permiso_para_funcionar     0.002513\n",
      "5       Capital               tipo_casa     0.002190\n",
      "2      Car√°cter        exp_cred_externa          NaN\n",
      "11    Colateral       montogarantiahipo          NaN\n",
      "\n",
      "üìà PESOS FINALES:\n",
      "   Car√°cter: 0.328\n",
      "   Capacidad: 0.167\n",
      "   Capital: 0.124\n",
      "   Condiciones: 0.091\n",
      "   Colateral: 0.290\n",
      "üìà Calculando scores por categor√≠a 5C...\n",
      "üéØ Calculando riesgo por valor (solo variables 5C's categ√≥ricas)...\n",
      "   Variables categ√≥ricas 5C's: 9\n",
      "\n",
      "======================================================================\n",
      "üìä REPORTE COMPLETO 5C DEL CR√âDITO (PESOS AUTOM√ÅTICOS)\n",
      "======================================================================\n",
      "\n",
      "üîß METODOLOG√çA DE PESOS:\n",
      "   - Mutual Information: Basado en dependencia estad√≠stica\n",
      "   - Random Forest: Basado en importancia en clasificaci√≥n\n",
      "   - Correlaci√≥n: Basado en relaci√≥n lineal con morosidad\n",
      "\n",
      "üîπ CAR√ÅCTER\n",
      "   Score: 58.64 / 100\n",
      "   Score ponderado: 19.25\n",
      "   Peso autom√°tico: 32.8%\n",
      "   Variables analizadas: 4\n",
      "   Interpretaci√≥n: Historial crediticio y comportamiento de pago\n",
      "   Contribuci√≥n por variable:\n",
      "     - exp_cred_interna: 100.00\n",
      "     - antigudad_domicilio: 67.74\n",
      "     - antiguedad_actividad: 66.19\n",
      "   Estado: ‚ö†Ô∏è  MODERADO\n",
      "\n",
      "üîπ CAPACIDAD\n",
      "   Score: 0.00 / 100\n",
      "   Score ponderado: 0.00\n",
      "   Peso autom√°tico: 16.7%\n",
      "   Variables analizadas: 1\n",
      "   Interpretaci√≥n: Capacidad de pago y estabilidad financiera\n",
      "   Contribuci√≥n por variable:\n",
      "     - cap_pago: 0.00\n",
      "   Estado: ‚ùå D√âBIL\n",
      "\n",
      "üîπ CAPITAL\n",
      "   Score: 10.24 / 100\n",
      "   Score ponderado: 1.27\n",
      "   Peso autom√°tico: 12.4%\n",
      "   Variables analizadas: 2\n",
      "   Interpretaci√≥n: Patrimonio y recursos propios\n",
      "   Contribuci√≥n por variable:\n",
      "     - tipo_casa: 15.48\n",
      "     - deudas: 5.01\n",
      "   Estado: ‚ùå D√âBIL\n",
      "\n",
      "üîπ CONDICIONES\n",
      "   Score: 24.38 / 100\n",
      "   Score ponderado: 2.22\n",
      "   Peso autom√°tico: 9.1%\n",
      "   Variables analizadas: 2\n",
      "   Interpretaci√≥n: Condiciones del pr√©stamo y entorno\n",
      "   Contribuci√≥n por variable:\n",
      "     - permiso_para_funcionar: 33.66\n",
      "     - comercio_en_region: 15.09\n",
      "   Estado: ‚ùå D√âBIL\n",
      "\n",
      "üîπ COLATERAL\n",
      "   Score: 30.13 / 100\n",
      "   Score ponderado: 8.73\n",
      "   Peso autom√°tico: 29.0%\n",
      "   Variables analizadas: 3\n",
      "   Interpretaci√≥n: Garant√≠as y respaldos\n",
      "   Contribuci√≥n por variable:\n",
      "     - montogarantialiq: 72.90\n",
      "     - montogarantiapre: 17.50\n",
      "     - montogarantiahipo: 0.00\n",
      "   Estado: ‚ùå D√âBIL\n",
      "\n",
      "üéØ SCORE TOTAL 5C: 31.46 / 100\n",
      "üö® PERFIL DE ALTO RIESGO - Se recomienda an√°lisis detallado\n",
      "\n",
      "üíæ Guardando resultados (solo variables 5C's)...\n",
      "   ‚úÖ pesos_variables_5c.csv - 12 variables\n",
      "   ‚úÖ scores_categorias_5c.csv - 5 categor√≠as\n",
      "   ‚úÖ pesos_automaticos_5c.csv - 5 categor√≠as\n",
      "   ‚úÖ riesgo_valores_5c.csv - 27 registros\n",
      "   ‚úÖ dataset_variables_5c.csv - 13 columnas\n",
      "   ‚úÖ contribuciones_variables_5c.csv - 12 variables\n",
      "üìà Analizando correlaciones entre variables 5C...\n",
      "üîÑ Preprocesando variables de las 5C's...\n",
      "   Variables preprocesadas: 12\n",
      "   üî• Mapa de calor generado: matriz_correlacion_5c.png\n",
      "   ‚úÖ correlaciones_altas_5c.csv - 0 pares detectados\n",
      "\n",
      "üéâ AN√ÅLISIS COMPLETADO EXITOSAMENTE\n",
      "üìÅ Archivos generados (solo variables 5C's):\n",
      "   - pesos_variables_5c.csv\n",
      "   - scores_categorias_5c.csv\n",
      "   - pesos_automaticos_5c.csv\n",
      "   - riesgo_valores_5c.csv (si hay variables categ√≥ricas)\n",
      "   - dataset_variables_5c.csv\n",
      "   - contribuciones_variables_5c.csv\n",
      "üìä Imagen exportada: matriz_correlacion_mixta.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class Analisis5CAutomaticoFiltrado:\n",
    "    def __init__(self, ruta_archivo):\n",
    "        self.ruta_archivo = ruta_archivo\n",
    "        self.df = None\n",
    "        self.C5 = {}\n",
    "        self.pesos_automaticos = {}\n",
    "        self.todas_variables_5c = []  # Lista de todas las variables de las 5C's\n",
    "        \n",
    "    def cargar_y_preparar_datos(self):\n",
    "        \"\"\"Cargar datos y crear variable target\"\"\"\n",
    "        print(\"üìä Cargando datos...\")\n",
    "        self.df = pd.read_csv(self.ruta_archivo)\n",
    "        \n",
    "        # Crear variable target\n",
    "        self.df[\"target\"] = self.df[\"diasmora\"].apply(lambda x: 1 if x > 7 else 0)\n",
    "        \n",
    "        # Eliminar columnas que no se usar√°n\n",
    "        columnas_eliminar = [\"nosocio\", \"nocredito\", \"sucursal\", \"diasmora\"]\n",
    "        self.df = self.df.drop(columns=[col for col in columnas_eliminar \n",
    "                                      if col in self.df.columns], errors='ignore')\n",
    "        \n",
    "        print(f\"‚úÖ Datos cargados: {self.df.shape[0]} registros, {self.df.shape[1]} variables\")\n",
    "        return self\n",
    "    \n",
    "    def definir_categorias_5c(self):\n",
    "        \"\"\"Definir las categor√≠as de las 5C y crear lista completa de variables\"\"\"\n",
    "        self.C5 = {\n",
    "            \"Car√°cter\": {\n",
    "                \"variables\": [\"reputaci√≥n_localidad\", \"antigudad_domicilio\", \"antiguedad_actividad\", \"exp_cred_externa\", \"exp_cred_interna\"],\n",
    "                \"interpretacion\": \"Historial crediticio y comportamiento de pago\"\n",
    "            },\n",
    "            \"Capacidad\": {\n",
    "                \"variables\": [\"cap_pago\"],\n",
    "                \"interpretacion\": \"Capacidad de pago y estabilidad financiera\"\n",
    "            },\n",
    "            \"Capital\": {\n",
    "                \"variables\": [\"tipo_casa\", \"deudas\"],\n",
    "                \"interpretacion\": \"Patrimonio y recursos propios\"\n",
    "            },\n",
    "            \"Condiciones\": {\n",
    "                \"variables\": [\"permiso_para_funcionar\", \"comercio_en_region\"],\n",
    "                \"interpretacion\": \"Condiciones del pr√©stamo y entorno\"\n",
    "            },\n",
    "            \"Colateral\": {\n",
    "                \"variables\": [\"montogarantialiq\", \"montogarantiapre\", \"montogarantiahipo\"],\n",
    "                \"interpretacion\": \"Garant√≠as y respaldos\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Filtrar solo variables existentes y crear lista completa\n",
    "        self.todas_variables_5c = []\n",
    "        for categoria, info in self.C5.items():\n",
    "            variables_existentes = [v for v in info[\"variables\"] if v in self.df.columns]\n",
    "            self.C5[categoria][\"variables\"] = variables_existentes\n",
    "            self.todas_variables_5c.extend(variables_existentes)\n",
    "            print(f\"   {categoria}: {len(variables_existentes)} variables\")\n",
    "        \n",
    "        print(f\"üìã Total variables 5C's: {len(self.todas_variables_5c)}\")\n",
    "        return self\n",
    "    \n",
    "    def preprocesar_variables_5c(self):\n",
    "        \"\"\"Preprocesar SOLO las variables de las 5C's\"\"\"\n",
    "        print(\"üîÑ Preprocesando variables de las 5C's...\")\n",
    "        \n",
    "        # Crear DataFrame solo con variables de las 5C's y target\n",
    "        columnas_a_mantener = self.todas_variables_5c + ['target']\n",
    "        df_5c = self.df[columnas_a_mantener].copy()\n",
    "        \n",
    "        # Codificar variables categ√≥ricas\n",
    "        label_encoders = {}\n",
    "        for col in df_5c.select_dtypes(include=['object']).columns:\n",
    "            if col != 'target':\n",
    "                le = LabelEncoder()\n",
    "                df_5c[col] = le.fit_transform(df_5c[col].astype(str))\n",
    "                label_encoders[col] = le\n",
    "        \n",
    "        # Escalar variables num√©ricas (excepto target)\n",
    "        numeric_cols = df_5c.select_dtypes(include=[np.number]).columns.drop('target', errors='ignore')\n",
    "        if len(numeric_cols) > 0:\n",
    "            scaler = StandardScaler()\n",
    "            df_5c[numeric_cols] = scaler.fit_transform(df_5c[numeric_cols])\n",
    "        \n",
    "        print(f\"   Variables preprocesadas: {len(df_5c.columns) - 1}\")\n",
    "        return df_5c, label_encoders\n",
    "    \n",
    "    def calcular_pesos_automaticos(self, mi_df):\n",
    "        \"\"\"Calcular pesos autom√°ticos para cada categor√≠a basado en los datos\"\"\"\n",
    "        print(\"‚öñÔ∏è Calculando pesos autom√°ticos para las 5C...\")\n",
    "\n",
    "        # ======================================================\n",
    "        # üîπ M√âTODO 1: Mutual Information\n",
    "        # ======================================================\n",
    "        pesos_mi = {}\n",
    "        total_mi = 0\n",
    "\n",
    "        for categoria, info in self.C5.items():\n",
    "            vars_cat = info[\"variables\"]\n",
    "            mi_cat = mi_df[mi_df[\"Variable\"].isin(vars_cat)]\n",
    "\n",
    "            if len(mi_cat) > 0:\n",
    "                prom = mi_cat[\"MI_Score\"].mean()\n",
    "                pesos_mi[categoria] = prom\n",
    "                total_mi += prom\n",
    "            else:\n",
    "                pesos_mi[categoria] = 0\n",
    "\n",
    "        if total_mi > 0:\n",
    "            pesos_mi = {k: v / total_mi for k, v in pesos_mi.items()}\n",
    "\n",
    "        # ======================================================\n",
    "        # üîπ M√âTODO 2: Random Forest Importance\n",
    "        # ======================================================\n",
    "        print(\"üå≤ Calculando importancia con Random Forest...\")\n",
    "        df_encoded, _ = self.preprocesar_variables_5c()\n",
    "        X = df_encoded.drop(columns=['target'])\n",
    "        y = df_encoded['target']\n",
    "\n",
    "        rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        rf.fit(X, y)\n",
    "\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Variable': X.columns,\n",
    "            'RF_Importance': rf.feature_importances_\n",
    "        })\n",
    "\n",
    "        pesos_rf = {}\n",
    "        total_rf = 0\n",
    "        for categoria, info in self.C5.items():\n",
    "            vars_cat = info[\"variables\"]\n",
    "            rf_cat = importance_df[importance_df[\"Variable\"].isin(vars_cat)]\n",
    "\n",
    "            if len(rf_cat) > 0:\n",
    "                prom = rf_cat[\"RF_Importance\"].mean()\n",
    "                pesos_rf[categoria] = prom\n",
    "                total_rf += prom\n",
    "            else:\n",
    "                pesos_rf[categoria] = 0\n",
    "\n",
    "        if total_rf > 0:\n",
    "            pesos_rf = {k: v / total_rf for k, v in pesos_rf.items()}\n",
    "\n",
    "        # ======================================================\n",
    "        # üîπ M√âTODO 3: CORRELACI√ìN AJUSTADA (CORREGIDO)\n",
    "        # ======================================================\n",
    "        print(\"üìä Calculando correlaciones (corregido)...\")\n",
    "\n",
    "        # Usar df codificado\n",
    "        df_corr = df_encoded.copy()\n",
    "\n",
    "        correlaciones = {}\n",
    "        valores_correlacion = []\n",
    "\n",
    "        for categoria, info in self.C5.items():\n",
    "            vars_cat = info[\"variables\"]\n",
    "\n",
    "            # Filtrar solo variables presentes en df codificado\n",
    "            vars_cat = [v for v in vars_cat if v in df_corr.columns]\n",
    "            if not vars_cat:\n",
    "                correlaciones[categoria] = 0\n",
    "                continue\n",
    "\n",
    "            # Correlaci√≥n absoluta media con target\n",
    "            corr_vals = df_corr[vars_cat].corrwith(df_corr[\"target\"]).abs()\n",
    "\n",
    "            corr_prom = corr_vals.mean() if len(corr_vals) else 0\n",
    "            correlaciones[categoria] = corr_prom\n",
    "\n",
    "            # Registrar detalles\n",
    "            for v, c in corr_vals.items():\n",
    "                valores_correlacion.append({\n",
    "                    \"Categoria\": categoria,\n",
    "                    \"Variable\": v,\n",
    "                    \"Correlacion\": c\n",
    "                })\n",
    "\n",
    "        # Normalizar\n",
    "        total_corr = sum(correlaciones.values())\n",
    "        if total_corr > 0:\n",
    "            correlaciones = {k: v / total_corr for k, v in correlaciones.items()}\n",
    "\n",
    "        # Mostrar correlaciones\n",
    "        print(\"\\nüìå Correlaciones detectadas:\")\n",
    "        df_corr_detalle = pd.DataFrame(valores_correlacion)\n",
    "        if not df_corr_detalle.empty:\n",
    "            print(df_corr_detalle.sort_values(\"Correlacion\", ascending=False).head(15))\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No se encontraron correlaciones num√©ricas para variables 5C.\")\n",
    "\n",
    "        # ======================================================\n",
    "        # üîπ M√âTODO COMBINADO FINAL\n",
    "        # ======================================================\n",
    "        pesos_finales = {}\n",
    "        for categoria in self.C5.keys():\n",
    "            valores = []\n",
    "\n",
    "            if pesos_mi[categoria] > 0:\n",
    "                valores.append(pesos_mi[categoria])\n",
    "            if pesos_rf[categoria] > 0:\n",
    "                valores.append(pesos_rf[categoria])\n",
    "            if correlaciones[categoria] > 0:\n",
    "                valores.append(correlaciones[categoria])\n",
    "\n",
    "            if valores:\n",
    "                pesos_finales[categoria] = sum(valores) / len(valores)\n",
    "            else:\n",
    "                pesos_finales[categoria] = 1 / len(self.C5)\n",
    "\n",
    "        # Normalizar pesos finales\n",
    "        total_final = sum(pesos_finales.values())\n",
    "        pesos_finales = {k: v / total_final for k, v in pesos_finales.items()}\n",
    "\n",
    "        self.pesos_automaticos = pesos_finales\n",
    "\n",
    "        print(\"\\nüìà PESOS FINALES:\")\n",
    "        for cat, peso in pesos_finales.items():\n",
    "            print(f\"   {cat}: {peso:.3f}\")\n",
    "\n",
    "        return pesos_finales, pesos_mi, pesos_rf, correlaciones\n",
    "\n",
    "    \n",
    "    def calcular_importancia_variables_5c(self):\n",
    "        \"\"\"Calcular importancia de variables SOLO de las 5C's usando Mutual Information\"\"\"\n",
    "        print(\"üîç Calculando importancia de variables (solo 5C's)...\")\n",
    "        \n",
    "        df_encoded, _ = self.preprocesar_variables_5c()\n",
    "        X = df_encoded.drop(columns=['target'], errors='ignore')\n",
    "        y = df_encoded['target']\n",
    "        \n",
    "        # Calcular Mutual Information\n",
    "        mi_scores = mutual_info_classif(X, y, random_state=42)\n",
    "        mi_df = pd.DataFrame({\n",
    "            'Variable': X.columns,\n",
    "            'MI_Score': mi_scores\n",
    "        }).sort_values('MI_Score', ascending=False)\n",
    "        \n",
    "        return mi_df\n",
    "    \n",
    "    def calcular_score_por_categoria(self, mi_df):\n",
    "        \"\"\"Calcular score para cada categor√≠a de las 5C usando pesos autom√°ticos\"\"\"\n",
    "        print(\"üìà Calculando scores por categor√≠a 5C...\")\n",
    "        \n",
    "        resultados = {}\n",
    "        \n",
    "        for categoria, info in self.C5.items():\n",
    "            variables_categoria = info[\"variables\"]\n",
    "            peso_categoria = self.pesos_automaticos.get(categoria, 0.2)\n",
    "            \n",
    "            # Filtrar importancia para variables de esta categor√≠a\n",
    "            mi_categoria = mi_df[mi_df['Variable'].isin(variables_categoria)]\n",
    "            \n",
    "            if len(mi_categoria) > 0:\n",
    "                # Score basado en importancia promedio normalizada\n",
    "                importancia_promedio = mi_categoria['MI_Score'].mean()\n",
    "                importancia_maxima = mi_df['MI_Score'].max()\n",
    "                score_normalizado = (importancia_promedio / importancia_maxima) * 100 if importancia_maxima > 0 else 0\n",
    "                \n",
    "                # Aplicar peso autom√°tico de la categor√≠a\n",
    "                score_ponderado = score_normalizado * peso_categoria\n",
    "                \n",
    "                # Calcular contribuci√≥n individual de variables\n",
    "                contribuciones = {}\n",
    "                for _, row in mi_categoria.iterrows():\n",
    "                    var = row['Variable']\n",
    "                    contrib = (row['MI_Score'] / importancia_maxima) * 100 if importancia_maxima > 0 else 0\n",
    "                    contribuciones[var] = contrib\n",
    "                \n",
    "                resultados[categoria] = {\n",
    "                    'score_raw': score_normalizado,\n",
    "                    'score_ponderado': score_ponderado,\n",
    "                    'peso_automatico': peso_categoria,\n",
    "                    'num_variables': len(mi_categoria),\n",
    "                    'variables_analizadas': variables_categoria,\n",
    "                    'importancia_promedio': importancia_promedio,\n",
    "                    'contribuciones_variables': contribuciones,\n",
    "                    'interpretacion': info['interpretacion']\n",
    "                }\n",
    "            else:\n",
    "                resultados[categoria] = {\n",
    "                    'score_raw': 0,\n",
    "                    'score_ponderado': 0,\n",
    "                    'peso_automatico': peso_categoria,\n",
    "                    'num_variables': 0,\n",
    "                    'variables_analizadas': [],\n",
    "                    'importancia_promedio': 0,\n",
    "                    'contribuciones_variables': {},\n",
    "                    'interpretacion': info['interpretacion']\n",
    "                }\n",
    "        \n",
    "        return resultados\n",
    "    \n",
    "    def calcular_riesgo_por_valor_5c(self):\n",
    "        \"\"\"Calcular riesgo por valor SOLO para variables categ√≥ricas de las 5C's\"\"\"\n",
    "        print(\"üéØ Calculando riesgo por valor (solo variables 5C's categ√≥ricas)...\")\n",
    "        \n",
    "        pesos_valores = []\n",
    "        \n",
    "        # Filtrar solo variables categ√≥ricas que est√°n en las 5C's\n",
    "        variables_categoricas_5c = [col for col in self.todas_variables_5c \n",
    "                                  if col in self.df.select_dtypes(include=['object']).columns]\n",
    "        \n",
    "        print(f\"   Variables categ√≥ricas 5C's: {len(variables_categoricas_5c)}\")\n",
    "        \n",
    "        for col in variables_categoricas_5c:\n",
    "            tabla_riesgo = self.df.groupby(col).agg({\n",
    "                'target': ['mean', 'count']\n",
    "            }).reset_index()\n",
    "            \n",
    "            tabla_riesgo.columns = ['Valor', 'Tasa_morosos', 'Conteo']\n",
    "            tabla_riesgo['Variable'] = col\n",
    "            tabla_riesgo['Riesgo_relativo'] = (tabla_riesgo['Tasa_morosos'] / \n",
    "                                             self.df['target'].mean()) * 100\n",
    "            \n",
    "            pesos_valores.append(tabla_riesgo)\n",
    "        \n",
    "        return pd.concat(pesos_valores, ignore_index=True) if pesos_valores else pd.DataFrame()\n",
    "    \n",
    "    def generar_reporte_5c(self, resultados_5c, pesos_detalle):\n",
    "        \"\"\"Generar reporte completo de las 5C\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"üìä REPORTE COMPLETO 5C DEL CR√âDITO (PESOS AUTOM√ÅTICOS)\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        total_score = sum([info['score_ponderado'] for info in resultados_5c.values()])\n",
    "        \n",
    "        # Mostrar metodolog√≠a de pesos\n",
    "        print(\"\\nüîß METODOLOG√çA DE PESOS:\")\n",
    "        print(\"   - Mutual Information: Basado en dependencia estad√≠stica\")\n",
    "        print(\"   - Random Forest: Basado en importancia en clasificaci√≥n\")\n",
    "        print(\"   - Correlaci√≥n: Basado en relaci√≥n lineal con morosidad\")\n",
    "        \n",
    "        for categoria, info in resultados_5c.items():\n",
    "            print(f\"\\nüîπ {categoria.upper()}\")\n",
    "            print(f\"   Score: {info['score_raw']:.2f} / 100\")\n",
    "            print(f\"   Score ponderado: {info['score_ponderado']:.2f}\")\n",
    "            print(f\"   Peso autom√°tico: {info['peso_automatico']*100:.1f}%\")\n",
    "            print(f\"   Variables analizadas: {info['num_variables']}\")\n",
    "            print(f\"   Interpretaci√≥n: {info['interpretacion']}\")\n",
    "            \n",
    "            # Mostrar contribuci√≥n de variables individuales\n",
    "            if info['contribuciones_variables']:\n",
    "                print(\"   Contribuci√≥n por variable:\")\n",
    "                for var, contrib in sorted(info['contribuciones_variables'].items(), \n",
    "                                         key=lambda x: x[1], reverse=True)[:3]:  # Top 3\n",
    "                    print(f\"     - {var}: {contrib:.2f}\")\n",
    "            \n",
    "            # Recomendaci√≥n basada en el score\n",
    "            if info['score_raw'] >= 70:\n",
    "                estado = \"‚úÖ FUERTE\"\n",
    "            elif info['score_raw'] >= 40:\n",
    "                estado = \"‚ö†Ô∏è  MODERADO\"\n",
    "            else:\n",
    "                estado = \"‚ùå D√âBIL\"\n",
    "            print(f\"   Estado: {estado}\")\n",
    "        \n",
    "        print(f\"\\nüéØ SCORE TOTAL 5C: {total_score:.2f} / 100\")\n",
    "        \n",
    "        # Interpretaci√≥n del score total\n",
    "        if total_score >= 70:\n",
    "            print(\"üåü EXCELENTE PERFIL CREDITICIO - Riesgo bajo\")\n",
    "        elif total_score >= 50:\n",
    "            print(\"üíº PERFIL MODERADO - Riesgo medio\")\n",
    "        else:\n",
    "            print(\"üö® PERFIL DE ALTO RIESGO - Se recomienda an√°lisis detallado\")\n",
    "    \n",
    "    def ejecutar_analisis_completo(self):\n",
    "        \"\"\"Ejecutar an√°lisis completo con pesos autom√°ticos\"\"\"\n",
    "        # Cargar y preparar datos\n",
    "        self.cargar_y_preparar_datos()\n",
    "        \n",
    "        # Definir categor√≠as 5C\n",
    "        self.definir_categorias_5c()\n",
    "        \n",
    "        # Calcular importancia de variables (solo 5C's)\n",
    "        mi_df = self.calcular_importancia_variables_5c()\n",
    "        \n",
    "        # Calcular pesos autom√°ticos\n",
    "        pesos_combinados, pesos_mi, pesos_rf, correlaciones = self.calcular_pesos_automaticos(mi_df)\n",
    "        \n",
    "        # Calcular scores por categor√≠a\n",
    "        resultados_5c = self.calcular_score_por_categoria(mi_df)\n",
    "        \n",
    "        # Calcular riesgo por valor (solo 5C's)\n",
    "        riesgo_valor_df = self.calcular_riesgo_por_valor_5c()\n",
    "        \n",
    "        # Generar reporte\n",
    "        self.generar_reporte_5c(resultados_5c, {\n",
    "            'MI': pesos_mi,\n",
    "            'RF': pesos_rf,\n",
    "            'Correlacion': correlaciones,\n",
    "            'Combinado': pesos_combinados\n",
    "        })\n",
    "        \n",
    "        # Guardar resultados (solo 5C's)\n",
    "        self.guardar_resultados_5c(mi_df, resultados_5c, riesgo_valor_df, pesos_combinados)\n",
    "        # üî• NUEVO: An√°lisis de correlaci√≥n\n",
    "        corr_matrix, correlaciones_altas_df = self.analizar_correlaciones_5c()\n",
    "        # Guardar correlaciones altas\n",
    "        if correlaciones_altas_df is not None:\n",
    "            correlaciones_altas_df.to_csv(\"./salidas_csv/correlaciones_altas_5c.csv\", index=False)\n",
    "            print(f\"   ‚úÖ correlaciones_altas_5c.csv - {len(correlaciones_altas_df)} pares detectados\")\n",
    "\n",
    "        \n",
    "        return resultados_5c, mi_df, riesgo_valor_df, pesos_combinados\n",
    "    \n",
    "    def guardar_resultados_5c(self, mi_df, resultados_5c, riesgo_valor_df, pesos_automaticos):\n",
    "        \"\"\"Guardar todos los resultados en archivos - SOLO VARIABLES 5C's\"\"\"\n",
    "        print(\"\\nüíæ Guardando resultados (solo variables 5C's)...\")\n",
    "        \n",
    "        # 1. Importancia de variables (solo 5C's)\n",
    "        mi_df.to_csv(\"./salidas_csv/pesos_variables_5c.csv\", index=False)\n",
    "        print(f\"   ‚úÖ pesos_variables_5c.csv - {len(mi_df)} variables\")\n",
    "        \n",
    "        # 2. Scores por categor√≠a 5C\n",
    "        scores_5c_df = pd.DataFrame([\n",
    "            {\n",
    "                'Categoria': cat,\n",
    "                'Score_Raw': info['score_raw'],\n",
    "                'Score_Ponderado': info['score_ponderado'],\n",
    "                'Peso_Automatico': info['peso_automatico'],\n",
    "                'Num_Variables': info['num_variables'],\n",
    "                'Importancia_Promedio': info['importancia_promedio'],\n",
    "                'Interpretacion': info['interpretacion']\n",
    "            }\n",
    "            for cat, info in resultados_5c.items()\n",
    "        ])\n",
    "        scores_5c_df.to_csv(\"./salidas_csv/scores_categorias_5c.csv\", index=False)\n",
    "        print(f\"   ‚úÖ scores_categorias_5c.csv - {len(scores_5c_df)} categor√≠as\")\n",
    "        \n",
    "        # 3. Pesos autom√°ticos\n",
    "        pesos_df = pd.DataFrame([\n",
    "            {'Categoria': cat, 'Peso': peso}\n",
    "            for cat, peso in pesos_automaticos.items()\n",
    "        ])\n",
    "        pesos_df.to_csv(\"./salidas_csv/pesos_automaticos_5c.csv\", index=False)\n",
    "        print(f\"   ‚úÖ pesos_automaticos_5c.csv - {len(pesos_df)} categor√≠as\")\n",
    "        \n",
    "        # 4. Riesgo por valor (solo variables categ√≥ricas 5C's)\n",
    "        if not riesgo_valor_df.empty:\n",
    "            riesgo_valor_df.to_csv(\"./salidas_csv/riesgo_valores_5c.csv\", index=False)\n",
    "            print(f\"   ‚úÖ riesgo_valores_5c.csv - {len(riesgo_valor_df)} registros\")\n",
    "        \n",
    "        # 5. Dataset filtrado con solo variables 5C's (para referencia)\n",
    "        df_5c = self.df[self.todas_variables_5c + ['target']]\n",
    "        df_5c.to_csv(\"./salidas_csv/dataset_variables_5c.csv\", index=False)\n",
    "        print(f\"   ‚úÖ dataset_variables_5c.csv - {len(df_5c.columns)} columnas\")\n",
    "        \n",
    "        # 6. Detalle de contribuciones por variable\n",
    "        contribuciones_data = []\n",
    "        for categoria, info in resultados_5c.items():\n",
    "            for variable, contrib in info['contribuciones_variables'].items():\n",
    "                contribuciones_data.append({\n",
    "                    'Categoria': categoria,\n",
    "                    'Variable': variable,\n",
    "                    'Contribucion_Score': contrib,\n",
    "                    'Importancia_Relativa': contrib * info['peso_automatico']\n",
    "                })\n",
    "        \n",
    "        if contribuciones_data:\n",
    "            contribuciones_df = pd.DataFrame(contribuciones_data)\n",
    "            contribuciones_df.to_csv(\"./contribuciones_variables_5c.csv\", index=False)\n",
    "            print(f\"   ‚úÖ contribuciones_variables_5c.csv - {len(contribuciones_df)} variables\")\n",
    "\n",
    "    def analizar_correlaciones_5c(self):\n",
    "        \"\"\"Analiza correlaciones entre variables 5C y genera justificaci√≥n autom√°tica.\"\"\"\n",
    "        print(\"üìà Analizando correlaciones entre variables 5C...\")\n",
    "\n",
    "        # üî• Usar variables 5C preprocesadas y codificadas\n",
    "        df_encoded, _ = self.preprocesar_variables_5c()\n",
    "        df_5c_numeric = df_encoded.drop(columns=['target'])\n",
    "\n",
    "        if df_5c_numeric.shape[1] < 2:\n",
    "            print(\"No hay suficientes variables num√©ricas para correlaci√≥n.\")\n",
    "            return None, None\n",
    "\n",
    "        # Matriz de correlaci√≥n\n",
    "        corr_matrix = df_5c_numeric.corr()\n",
    "\n",
    "        # Detectar correlaciones altas\n",
    "        correlaciones_altas = []\n",
    "        umbral = 0.65  # Ajustable\n",
    "        for col1 in corr_matrix.columns:\n",
    "            for col2 in corr_matrix.columns:\n",
    "                if col1 < col2:  # Evitar duplicados\n",
    "                    corr_val = corr_matrix.loc[col1, col2]\n",
    "                    if abs(corr_val) >= umbral:\n",
    "                        correlaciones_altas.append({\n",
    "                            \"Variable_1\": col1,\n",
    "                            \"Variable_2\": col2,\n",
    "                            \"Correlacion\": corr_val,\n",
    "                            \"Justificacion\": self.generar_justificacion_correlacion(col1, col2, corr_val)\n",
    "                        })\n",
    "\n",
    "        correlaciones_altas_df = pd.DataFrame(correlaciones_altas)\n",
    "\n",
    "        # Guardar mapa de calor\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "        plt.title(\"Matriz de Correlaci√≥n entre Variables 5C (Codificadas)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"./salidas_csv/matriz_correlacion_5c.png\")\n",
    "        plt.close()\n",
    "\n",
    "        print(\"   üî• Mapa de calor generado: matriz_correlacion_5c.png\")\n",
    "        return corr_matrix, correlaciones_altas_df\n",
    "\n",
    "\n",
    "    def cramers_v(self,conf_matrix):\n",
    "        chi2 = chi2_contingency(conf_matrix)[0]\n",
    "        n = conf_matrix.sum().sum()\n",
    "        phi2 = chi2 / n\n",
    "        r,k = conf_matrix.shape\n",
    "        phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "        rcorr = r - ((r-1)**2)/(n-1)\n",
    "        kcorr = k - ((k-1)**2)/(n-1)\n",
    "        return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n",
    "\n",
    "    def correlation_ratio(self,categories, values):\n",
    "        categories = np.array(categories)\n",
    "        values = np.array(values)\n",
    "        fcat, _ = pd.factorize(categories)\n",
    "        cat_means = [values[fcat==i].mean() for i in range(len(np.unique(fcat)))]\n",
    "        overall_mean = values.mean()\n",
    "        numerator = sum([len(values[fcat==i]) * (cat_means[i] - overall_mean)**2 for i in range(len(np.unique(fcat)))])\n",
    "        denominator = sum((values - overall_mean)**2)\n",
    "        return np.sqrt(numerator / denominator) if denominator != 0 else 0\n",
    "\n",
    "    def matriz_correlacion_mixta(self):\n",
    "        df = self.df.copy()\n",
    "        columnas = self.todas_variables_5c\n",
    "\n",
    "        # Matriz vac√≠a\n",
    "        matriz = pd.DataFrame(index=columnas, columns=columnas, dtype=float)\n",
    "\n",
    "        def tipo(col):\n",
    "            return \"num\" if np.issubdtype(df[col].dtype, np.number) else \"cat\"\n",
    "\n",
    "        for col1 in columnas:\n",
    "            for col2 in columnas:\n",
    "\n",
    "                # 1. Diagonal = 1\n",
    "                if col1 == col2:\n",
    "                    matriz.loc[col1, col2] = 1.0\n",
    "                    continue\n",
    "\n",
    "                t1, t2 = tipo(col1), tipo(col2)\n",
    "\n",
    "                # 2. Pearson\n",
    "                if t1 == \"num\" and t2 == \"num\":\n",
    "                    matriz.loc[col1, col2] = df[col1].corr(df[col2])\n",
    "\n",
    "                # 3. Cram√©r V\n",
    "                elif t1 == \"cat\" and t2 == \"cat\":\n",
    "                    tabla = pd.crosstab(df[col1], df[col2])\n",
    "                    matriz.loc[col1, col2] = self.cramers_v(tabla)\n",
    "\n",
    "                # 4. Correlation Ratio Œ∑\n",
    "                else:\n",
    "                    if t1 == \"cat\":\n",
    "                        categorias, valores = df[col1], df[col2]\n",
    "                    else:\n",
    "                        categorias, valores = df[col2], df[col1]\n",
    "\n",
    "                    matriz.loc[col1, col2] = self.correlation_ratio(categorias, valores)\n",
    "\n",
    "        return matriz\n",
    "\n",
    "    def generar_justificacion_correlacion(self, var1, var2, corr_val):\n",
    "        \"\"\"Genera una justificaci√≥n interpretativa del por qu√© dos variables se correlacionan.\"\"\"\n",
    "        signo = \"positiva\" if corr_val > 0 else \"negativa\"\n",
    "\n",
    "        explicaciones_generales = [\n",
    "            f\"Ambas variables podr√≠an estar midiendo dimensiones similares del comportamiento crediticio.\",\n",
    "            f\"Es com√∫n que caracter√≠sticas relacionadas al historial o estabilidad econ√≥mica est√©n correlacionadas.\",\n",
    "            f\"Variables que reflejan capacidad de pago o estabilidad pueden evolucionar de manera conjunta.\",\n",
    "            f\"Este patr√≥n sugiere que ambas variables captan informaci√≥n redundante del solicitante.\"\n",
    "        ]\n",
    "\n",
    "        # Justificaci√≥n espec√≠fica basada en palabras clave\n",
    "        if \"garantia\" in var1 and \"garantia\" in var2:\n",
    "            motivo = \"Ambas variables describen distintos tipos de garant√≠as, lo cual naturalmente genera dependencia.\"\n",
    "        elif \"antiguedad\" in var1 or \"antiguedad\" in var2:\n",
    "            motivo = \"La antig√ºedad suele ir acompa√±ada de estabilidad econ√≥mica, por lo que estas variables tienden a correlacionarse.\"\n",
    "        elif \"exp_cred\" in var1 or \"exp_cred\" in var2:\n",
    "            motivo = \"La experiencia crediticia refleja comportamiento hist√≥rico, por lo que es com√∫n que variables de historial se relacionen.\"\n",
    "        elif \"cap\" in var1 or \"cap\" in var2:\n",
    "            motivo = \"Las variables de capacidad de pago pueden estar influenciadas por ingresos, antig√ºedad y tipo de actividad.\"\n",
    "        elif \"deuda\" in var1 or \"deuda\" in var2:\n",
    "            motivo = \"Niveles de deuda y patrimonio suelen estar estad√≠sticamente relacionados.\"\n",
    "        else:\n",
    "            motivo = np.random.choice(explicaciones_generales)\n",
    "\n",
    "        return f\"Correlaci√≥n {signo} entre {var1} y {var2}. {motivo}\"\n",
    "\n",
    "    def graficar_matriz_mixta(self, matriz):\n",
    "        plt.figure(figsize=(20, 18))\n",
    "\n",
    "        sns.heatmap(\n",
    "            matriz.astype(float),\n",
    "            cmap=\"coolwarm\",\n",
    "            center=0,\n",
    "            linewidths=0.5,\n",
    "            square=True,\n",
    "            cbar_kws={\"label\": \"Correlaci√≥n\"}\n",
    "        )\n",
    "\n",
    "        plt.title(\"Matriz de Correlaci√≥n Mixta (Pearson / Cram√©r / Eta)\", fontsize=16)\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"./salidas_img/matriz_correlacion_mixta.png\", dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        print(\"üìä Imagen exportada: matriz_correlacion_mixta.png\")\n",
    "    \n",
    "    \n",
    "    # === EJECUCI√ìN PRINCIPAL ===\n",
    "if __name__ == \"__main__\":\n",
    "    # Inicializar y ejecutar an√°lisis\n",
    "    analizador = Analisis5CAutomaticoFiltrado(\"./../Registros_sin_nulos.csv\")\n",
    "    resultados, mi_df, riesgo_df, pesos_auto = analizador.ejecutar_analisis_completo()\n",
    "    \n",
    "    print(f\"\\nüéâ AN√ÅLISIS COMPLETADO EXITOSAMENTE\")\n",
    "    print(f\"üìÅ Archivos generados (solo variables 5C's):\")\n",
    "    print(f\"   - pesos_variables_5c.csv\")\n",
    "    print(f\"   - scores_categorias_5c.csv\") \n",
    "    print(f\"   - pesos_automaticos_5c.csv\")\n",
    "    print(f\"   - riesgo_valores_5c.csv (si hay variables categ√≥ricas)\")\n",
    "    print(f\"   - dataset_variables_5c.csv\")\n",
    "    print(f\"   - contribuciones_variables_5c.csv\")\n",
    "\n",
    "    #corr_df = analizador.analizar_correlaciones_mixto()\n",
    "    matriz = analizador.matriz_correlacion_mixta()\n",
    "    analizador.graficar_matriz_mixta(matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c0b3f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0743a87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
